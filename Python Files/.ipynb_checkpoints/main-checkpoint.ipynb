{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b883f0a9",
   "metadata": {},
   "source": [
    "## Main File for Project! All important functions are here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d33acc5",
   "metadata": {},
   "source": [
    "#### Jack Cells / Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install os\n",
    "%pip install numpy\n",
    "%pip install segment_anything\n",
    "%pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor, sam_model_registry, SamAutomaticMaskGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_for_point(image_path, point, model_type=\"default\", checkpoint_path=None):\n",
    "    try:\n",
    "        # Load SAM model\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            raise FileNotFoundError(f\"Checkpoint file not found at: {checkpoint_path}\")\n",
    "        sam = sam_model_registry[model_type](checkpoint=checkpoint_path)\n",
    "        predictor = SamPredictor(sam)\n",
    "\n",
    "        # Load/set img\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        predictor.set_image(image)\n",
    "\n",
    "        # Generate mask\n",
    "        input_point = np.array([point])\n",
    "        input_label = np.array([1])  # For foreground\n",
    "        masks, _, _ = predictor.predict(\n",
    "            point_coords=input_point,\n",
    "            point_labels=input_label,\n",
    "            multimask_output=False,  # Return only the best mask\n",
    "        )\n",
    "        return masks[0]  # Return the first mask (best mask)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = \"test.jpg\"\n",
    "checkpoint_path_small = \"sam_vit_b_01ec64.pth\"\n",
    "point = (1000, 1000) \n",
    "\n",
    "mask = get_mask_for_point(image_path, point, model_type=\"vit_b\", checkpoint_path=checkpoint_path_small)\n",
    "\n",
    "if mask is not None:\n",
    "    print(\"Mask shape:\", mask.shape)\n",
    "    # You can further process or display the mask here.  For example:\n",
    "    import matplotlib.pyplot as plt\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(mask, cmap='gray', alpha=0.5)  # Overlay the mask\n",
    "    plt.scatter(point[0], point[1], c='red', s=10) # added line\n",
    "    plt.title('Image with Mask Overlay')\n",
    "    plt.show()\n",
    "\n",
    "else: print(\"Failed to generate mask.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd27eae-3c1f-4c89-92d3-cb3872130405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21ab95e6-ca7f-4407-9a8c-3c597055f0f1",
   "metadata": {},
   "source": [
    "# main.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c10855-cba0-4f64-970e-e0172961a891",
   "metadata": {},
   "source": [
    "In this notebook, we walk through our methods for detecting the positions of darts on a dartboard, and returning a score based on their positions. We have a few different methods we tried to implement, and experimented with many ideas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128199df-702f-4420-9343-229e46ddaf1a",
   "metadata": {},
   "source": [
    "plan for sections to include underneath this (to show our thought process). We can delete this after we place all our code in\n",
    "\n",
    "NAIVE IMPLEMENTATION:\n",
    "- First, some experimentation with the frontal view\n",
    "  - make it clear that while this is easier for a user, a front view of the darts just does not provide enough information about the locations of the tips. In many cases, you cannot see where the tips hit the board by taking an image from this position\n",
    "  - show how when doing a difference check between a blank board and one with darts, the changes in orientation cause it to be hard to pinpoint where darts landed, let alone where their tips are\n",
    "- Show our idea with taking a photo from the right side of the board, and then computing a homography to warp it into a frontal view. It gives us the best of both worlds: the information gained by looking from the side, but also a frontal view that allows us to standardize our scoring (we get the same size photo each time, with the center of the board centered thanks to the ArUco's)\n",
    "- Maybe briefly mention that we attempted some template matching.. and while it was successful in cropping the board, the issues of scale (sometimes someone would be farther away when they took the picture of the board, sometimes closer) ended up causing issues. Having to search for versions of the template that were smaller took a lot of time compared to using pre-placed ArUco's.\n",
    "- So, now we are at the point where we have a warped frontal image of the board.. show how we initially tried to detect darts\n",
    "  - this would be by using a neon yellow mask, yellow darts, and finding countours (taking the farthest right point)\n",
    "- Show how we intially converted these locations on the image to score (physical COCO Json mapping)\n",
    "\n",
    "EXTENSIONS:\n",
    "- how can we find regions of the dartboard without a manually generated mapping? If we want this to be able to work well on any dart board, we cannot assume that ArUco's will get us the same homography every time.. we need something more robust which can look at the image and find regions (enter Rachel's ideas and code + some of reed's)\n",
    "- How can we detect darts without the need for spray painting them neon yellow? (enter Jonathan's work with ML)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
